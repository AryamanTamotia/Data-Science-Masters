{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91fc6548-6e1f-4034-bcd5-0c5e377cb6dc",
   "metadata": {},
   "source": [
    "# 21 February 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03caf614-4b98-4ab6-a635-96609a8ed09d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f94cf-59ed-4222-8c22-ff61cd48c412",
   "metadata": {},
   "source": [
    "Web scraping, also known as web data extraction or web harvesting, is the process of extracting data from websites. It involves using tools or scripts to crawl through the website, extracting the desired data and storing it in a structured format such as a CSV file or database.\n",
    "\n",
    "Web scraping is used for various purposes, including:\n",
    "\n",
    "1. Business Intelligence: Businesses use web scraping to gather data on competitors, market trends, customer preferences, and other information that can help them make informed decisions.\n",
    "\n",
    "2. Research: Researchers use web scraping to collect data for academic or scientific purposes, such as analyzing social media trends or tracking changes in public opinion.\n",
    "\n",
    "3. Content Aggregation: Websites use web scraping to gather content from other websites automatically and display it on their own site.\n",
    "\n",
    "Some specific areas where web scraping is used to get data include:\n",
    "\n",
    "1. E-commerce: Web scraping can be used to gather product information, pricing, and customer reviews from e-commerce websites.\n",
    "\n",
    "2. Job Search: Web scraping can be used to collect job listings from multiple job boards to create a comprehensive database.\n",
    "\n",
    "3. Real Estate: Web scraping can be used to gather property data, such as pricing, square footage, and location, from real estate websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dd55d-66b0-4d2b-a36b-d0f4c97d86cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0f81f-e362-4238-b080-053d50a93ff5",
   "metadata": {},
   "source": [
    "There are several methods that can be used for web scraping, including:\n",
    "\n",
    "1. Regular expressions: A pattern matching technique to extract data from HTML or XML code.\n",
    "\n",
    "2. HTML parsers: A set of tools that parse HTML and XML documents and create a tree-like structure that can be searched and manipulated.\n",
    "\n",
    "3. Web scraping libraries: A set of Python libraries that can be used to scrape data from websites, including BeautifulSoup, Scrapy, and Selenium.\n",
    "\n",
    "4. APIs: Many websites provide APIs (Application Programming Interfaces) that allow users to access data programmatically.\n",
    "\n",
    "5. Headless browsers: A browser that can be run in the background without any visible user interface, and can be used to interact with websites programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67e10b-e1fb-427b-9bef-3ccc29ae0c7d",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706fc379-2917-4acd-9f86-3ec4d4469fb8",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner.\n",
    "\n",
    "Beautiful Soup is commonly used for web scraping tasks such as data mining, web content extraction, and automated testing of web applications. It can be particularly useful in scenarios where the data is spread across multiple pages, making it difficult to manually extract the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20be00-0399-4660-980c-de6220b9fa88",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d4d7a-2db6-4c7f-bb61-a9fdfd0b40b8",
   "metadata": {},
   "source": [
    "Flask is a lightweight web application framework that allows us to easily create and deploy web applications. In the context of web scraping, Flask can be used to create a web application that can scrape data from various websites and display it to the user in a readable format. Flask can be used in web scraping projects to create a user-friendly interface for scraping and displaying data from various websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c06c5-dbfa-4ec3-8539-68305a905ed1",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e81573-20fe-4014-8a06-2e39d6f60c1c",
   "metadata": {},
   "source": [
    "1. Elastic Beanstalk:\n",
    "\n",
    "Elastic Beanstalk is a fully managed service that makes it easy to deploy and run web applications. It automates the process of deploying and scaling applications by handling the deployment details such as provisioning resources, load balancing, and auto-scaling. Elastic Beanstalk supports several programming languages, including Java, .NET, PHP, Node.js, Python, Ruby, and Go. It allows developers to focus on writing code and lets AWS handle the infrastructure management. Elastic Beanstalk provides a simple web interface and a command-line interface for deploying, monitoring, and managing applications.\n",
    "\n",
    "2. CodePipeline:\n",
    "\n",
    "CodePipeline is a continuous delivery service that helps developers automate the software release process. It allows developers to build, test, and deploy applications quickly and reliably. CodePipeline integrates with other AWS services such as CodeCommit, CodeBuild, and CodeDeploy to automate the entire application release process. Developers can create pipelines that automatically build, test, and deploy code changes to different environments such as development, staging, and production. CodePipeline provides a visual representation of the entire release process and provides real-time updates on the status of the release."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
